<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Parsing natural language &mdash; Graphbrain 0.6.0-dev documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/favicon.png"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Readers" href="readers.html" />
    <link rel="prev" title="Discovering patterns" href="discovering-patterns.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #333" >
            <a href="../index.html">
            <img src="../_static/graphbrain-logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
    <div>
    <a href="https://socsemics.huma-num.fr/" style="margin:0px; text-align:center">
        <img style="width: 75%; height: 75%; border-radius: 0px; margin:0px; padding:5px; background:#ffffff" src="/_static/socsemics.png"/>
    </a>
    </div>
    
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials.html">Tutorials and examples</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../manual.html">Manual</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="overview.html">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="notation.html">Semantic Hypergraph notation</a></li>
<li class="toctree-l2"><a class="reference internal" href="special-relations.html">Special relations</a></li>
<li class="toctree-l2"><a class="reference internal" href="hypergraph-operations.html">Basic hypergraph operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="patterns.html">Patterns</a></li>
<li class="toctree-l2"><a class="reference internal" href="discovering-patterns.html">Discovering patterns</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Parsing natural language</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#lemmas">Lemmas</a></li>
<li class="toctree-l3"><a class="reference internal" href="#parser-level-coreference-resolution-and-inference-of-gender-number-and-animacy">Parser-level coreference resolution and inference of gender, number and animacy</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="readers.html">Readers</a></li>
<li class="toctree-l2"><a class="reference internal" href="corefs.html">Co-reference resolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="meaning.html">Meaning extraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="backends.html">Hypergraph database backends</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks.html">Notebooks and visualizations</a></li>
<li class="toctree-l2"><a class="reference internal" href="cli.html">Command-line interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="internals.html">Internals and extending Graphbrain</a></li>
<li class="toctree-l2"><a class="reference internal" href="api.html">API reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../team.html">Team</a></li>
<li class="toctree-l1"><a class="reference internal" href="../thanks.html">Thanks</a></li>
</ul>


        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #333" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Graphbrain</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../manual.html">Manual</a> &raquo;</li>
      <li>Parsing natural language</li>
      <li class="wy-breadcrumbs-aside">
              <!-- User defined GitHub URL -->
              <a href="https://github.com/graphbrain/graphbrain" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="parsing-natural-language">
<h1>Parsing natural language<a class="headerlink" href="#parsing-natural-language" title="Permalink to this headline"></a></h1>
<p>Parsing natural language to semantic hypergraphs is another crucial aspect of Graphbrain. This aspect of the library is covered by the <code class="docutils literal notranslate"><span class="pre">graphbrain.parsers</span></code> package. Let us see how to create a parser, and how to use it to parse a sentence:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">graphbrain.parsers</span> <span class="kn">import</span> <span class="n">create_parser</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">parser</span> <span class="o">=</span> <span class="n">create_parser</span><span class="p">(</span><span class="n">lang</span><span class="o">=</span><span class="s1">&#39;en&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">parse_results</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s1">&#39;Einstein first published the theory of relativity in 1905&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">parse_results</span><span class="p">[</span><span class="s1">&#39;parses&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;main_edge&#39;</span><span class="p">]</span>
<span class="go">((first/M/en published/Pd.sox.&lt;f-----/en) einstein/Cp.s/en (of/Br.ma/en (the/Md/en theory/Cc.s/en) relativity/Cc.s/en) (in/Tt/en 1905/C#/en))</span>
</pre></div>
</div>
<p>Notice that <code class="docutils literal notranslate"><span class="pre">create_parser()</span></code> takes a some time (10 to 20 seconds is normal), because it has to load the underlying language models. Here we pass it the only mandatory parameter, which is the name of the parser to use. This will typically correspond to the language to parse. Currently only one parser for English is provided (“en”), but Graphbrain already comes with auxiliary scripts to help in the development of parsers for other languages.</p>
<p>We also see that we specify a position in the <code class="docutils literal notranslate"><span class="pre">parse_results</span></code> data structure (at the top-level, it is a dictionary) to directly access the hyperedge that corresponds to the parsed sentence. This is because <code class="docutils literal notranslate"><span class="pre">parse_results</span></code> includes useful additional information about the parsed text, and also because the parsed text can correspond to more than one hyperedge. So let us take a look at the full contents of <code class="docutils literal notranslate"><span class="pre">parse_results</span></code> from the example above:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">parse_results</span>
<span class="go">{&#39;parses&#39;:</span>
<span class="go">    ({&#39;main_edge&#39;: ((first/M/en published/Pd.sox.&lt;f-----/en) einstein/Cp.s/en (of/Br.ma/en (the/Md/en theory/Cc.s/en) relativity/Cc.s/en) (in/Tt/en 1905/C#/en)),</span>
<span class="go">      &#39;extra_edges&#39;: set(),</span>
<span class="go">      &#39;failed&#39;: False,</span>
<span class="go">      &#39;text&#39;: &#39;Einstein first published the theory of relativity in 1905&#39;,</span>
<span class="go">      &#39;atom2word&#39;: {first/M/en: (&#39;first&#39;, 1),</span>
<span class="go">                    published/Pd.sox.&lt;f-----/en: (&#39;published&#39;, 2),</span>
<span class="go">                    einstein/Cp.s/en: (&#39;Einstein&#39;, 0),</span>
<span class="go">                    of/Br.ma/en: (&#39;of&#39;, 5),</span>
<span class="go">                    the/Md/en: (&#39;the&#39;, 3),</span>
<span class="go">                    theory/Cc.s/en: (&#39;theory&#39;, 4),</span>
<span class="go">                    relativity/Cc.s/en: (&#39;relativity&#39;, 6),</span>
<span class="go">                    in/Tt/en: (&#39;in&#39;, 7),</span>
<span class="go">                    1905/C#/en: (&#39;1905&#39;, 8)},</span>
<span class="go">      &#39;atom2token&#39;: {einstein/Cp.s/en: Einstein,</span>
<span class="go">                     first/M/en: first,</span>
<span class="go">                     published/Pd.sox.&lt;f-----/en: published: published,</span>
<span class="go">                     the/Md/en: the,</span>
<span class="go">                     theory/Cc.s/en: theory,</span>
<span class="go">                     of/Br.ma/en: of,</span>
<span class="go">                     relativity/Cc.s/en: relativity,</span>
<span class="go">                     in/Tt/en: in,</span>
<span class="go">                     1905/C#/en: 1905},</span>
<span class="go">      &#39;spacy_sentence&#39;: Einstein first published the theory of relativity in 1905},),</span>
<span class="go"> &#39;inferred_edges&#39;: []}</span>
</pre></div>
</div>
<p>At the top level we have <code class="docutils literal notranslate"><span class="pre">parses</span></code> and <code class="docutils literal notranslate"><span class="pre">inferred_edges</span></code>. <code class="docutils literal notranslate"><span class="pre">parses</span></code> is a list of parse information for each sentence identified in the parse text, while <code class="docutils literal notranslate"><span class="pre">inferred_edges</span></code> contains all inferences that could be derived during the parse stage from the entire piece of text that was provided. Here this latter field is empty. In the section about coreference resolution, we will see how it can be populated.</p>
<p>Each parse dictionary (i.e. each item in <code class="docutils literal notranslate"><span class="pre">parses</span></code>, corresponding to one sentence), contains the following fields:</p>
<ul class="simple">
<li><p>‘main_edge’: contains the hyperedge that directly corresponds to the sentence.</p></li>
<li><p>‘extra_edges’: contains additional edges derived from the sentence. Here it is empty, but we will see that it can be populated, for example, with lemma relationships.</p></li>
<li><p>‘failed’: indicates if the parse was considered to have failed.</p></li>
<li><p>‘text’: the text of the sentence that corresponds to this parse.</p></li>
<li><p>‘atom2word’: a dictionary of correspondences from each atom in the main_edge to a word in the sentence. The word is represented by a tuple, where the first element is the string of the word itself, while the second indicates the position of this word in the sentence.</p></li>
<li><p>‘atom2token’: a dictionary of correspondences from each atom in the main_edge to the spaCy token from which it was derived.</p></li>
<li><p>‘spacy_sentence’: the spaCy structure representing the sentence.</p></li>
</ul>
<section id="lemmas">
<h2>Lemmas<a class="headerlink" href="#lemmas" title="Permalink to this headline"></a></h2>
<p>When creating a parser, it is possible to require it to also produce lemma relationships. Lemmas are linguistic roots of words, for example the infinitive tense of a verb or the singular form of a known. They are represented by Graphbrain in hyperedges like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">lemma</span><span class="o">/</span><span class="n">J</span><span class="o">/.</span> <span class="n">published</span><span class="o">/</span><span class="n">P</span><span class="o">/</span><span class="n">en</span> <span class="n">publish</span><span class="o">/</span><span class="n">P</span><span class="o">/</span><span class="n">en</span><span class="p">)</span>
</pre></div>
</div>
<p>The special conjunction <code class="docutils literal notranslate"><span class="pre">lemma/J/.</span></code> indicates a lemma specification, followed by the atom and its lemma form. Notice that only the main type is considered and other role information is removed, because these are not relevant to the lemma relationship and would reduce generality. Let us see the example above with lemmas enabled:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">graphbrain.parsers</span> <span class="kn">import</span> <span class="n">create_parser</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">parser</span> <span class="o">=</span> <span class="n">create_parser</span><span class="p">(</span><span class="n">lang</span><span class="o">=</span><span class="s1">&#39;en&#39;</span><span class="p">,</span> <span class="n">lemmas</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">parser</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s1">&#39;Einstein first published the theory of relativity in 1905&#39;</span><span class="p">)</span>
<span class="go">{&#39;parses&#39;:</span>
<span class="go">    ({&#39;main_edge&#39;: ((first/M/en published/Pd.sox.&lt;f-----/en) einstein/Cp.s/en (of/Br.ma/en (the/Md/en theory/Cc.s/en) relativity/Cc.s/en) (in/Tt/en 1905/C#/en)),</span>
<span class="go">      &#39;extra_edges&#39;: {(lemma/J/. theory/C/en theory/C/en),</span>
<span class="go">                      (lemma/J/. einstein/C/en einstein/C/en),</span>
<span class="go">                      (lemma/J/. relativity/C/en relativity/C/en),</span>
<span class="go">                      (lemma/J/. 1905/C/en 1905/C/en),</span>
<span class="go">                      (lemma/J/. first/M/en first/M/en),</span>
<span class="go">                      (lemma/J/. published/P/en publish/P/en),</span>
<span class="go">                      (lemma/J/. of/B/en of/B/en),</span>
<span class="go">                      (lemma/J/. the/M/en the/M/en),</span>
<span class="go">                      (lemma/J/. in/T/en in/T/en)},</span>
<span class="go">      &#39;failed&#39;: False,</span>
<span class="go">      &#39;text&#39;: &#39;Einstein first published the theory of relativity in 1905&#39;,</span>
<span class="go">      &#39;atom2word&#39;: {first/M/en: (&#39;first&#39;, 1),</span>
<span class="go">                    published/Pd.sox.&lt;f-----/en: (&#39;published&#39;, 2),</span>
<span class="go">                    einstein/Cp.s/en: (&#39;Einstein&#39;, 0),</span>
<span class="go">                    of/Br.ma/en: (&#39;of&#39;, 5),</span>
<span class="go">                    the/Md/en: (&#39;the&#39;, 3),</span>
<span class="go">                    theory/Cc.s/en: (&#39;theory&#39;, 4),</span>
<span class="go">                    relativity/Cc.s/en: (&#39;relativity&#39;, 6),</span>
<span class="go">                    in/Tt/en: (&#39;in&#39;, 7),</span>
<span class="go">                    1905/C#/en: (&#39;1905&#39;, 8)},</span>
<span class="go">      &#39;atom2token&#39;: {einstein/Cp.s/en: Einstein,</span>
<span class="go">                     first/M/en: first,</span>
<span class="go">                     the/Md/en: the,</span>
<span class="go">                     theory/Cc.s/en: theory,</span>
<span class="go">                     relativity/Cc.s/en: relativity,</span>
<span class="go">                     1905/C#/en: 1905,</span>
<span class="go">                     published/Pd.sox.&lt;f-----/en: published,</span>
<span class="go">                     of/Br.ma/en: of, in/Tt/en: in},</span>
<span class="go">      &#39;spacy_sentence&#39;: Einstein first published the theory of relativity in 1905},),</span>
<span class="go"> &#39;inferred_edges&#39;: []}</span>
</pre></div>
</div>
</section>
<section id="parser-level-coreference-resolution-and-inference-of-gender-number-and-animacy">
<h2>Parser-level coreference resolution and inference of gender, number and animacy<a class="headerlink" href="#parser-level-coreference-resolution-and-inference-of-gender-number-and-animacy" title="Permalink to this headline"></a></h2>
<p><strong>NOTE:</strong> Currently, the default distribution of Graphbrain does not support parser-level coreference resolution. Please refer to the installation instructions on how to build graphbrain with this feature.</p>
<p>Currently, parser-level coreference resolution relies on neuralcoref, which requires Python ==3.7 and spaCy &gt;=2.1.0, &lt;3.0.0. These restrictions are the reason why we kept it out of the default distribution. Once the successor of neuralcoref is released, we hope to use it to enable parser-level coreference resolution by default in the default distribution.</p>
<p>Consider the sentence:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="s2">&quot;Alice says that she likes her dog.&quot;</span>
</pre></div>
</div>
<p>Parser-level coreference resolution identifies that the pronouns “she” and “her” in the above sentence refer to “Alice”. It then extends the parser_results with the <code class="docutils literal notranslate"><span class="pre">resolved_corefs</span></code> field, containing a hyperedge where such indirect references are made explicit:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">says</span><span class="o">/</span><span class="n">Pd</span><span class="o">.</span><span class="n">sr</span> <span class="n">alice</span><span class="o">/</span><span class="n">C</span> <span class="p">(</span><span class="n">that</span><span class="o">/</span><span class="n">T</span> <span class="p">(</span><span class="n">likes</span><span class="o">/</span><span class="n">P</span><span class="o">.</span><span class="n">so</span> <span class="n">alice</span><span class="o">/</span><span class="n">C</span> <span class="p">(</span><span class="n">poss</span><span class="o">/</span><span class="n">Bp</span><span class="o">.</span><span class="n">am</span><span class="o">/.</span> <span class="n">alice</span><span class="o">/</span><span class="n">C</span> <span class="n">dog</span><span class="o">/</span><span class="n">C</span><span class="p">))))</span>
</pre></div>
</div>
<p>Notice that the special builder <code class="docutils literal notranslate"><span class="pre">poss/Bp.am</span></code>, meant to indicate a general possessive construct, is employed to represent “her dog” explicitly as <code class="docutils literal notranslate"><span class="pre">(poss/Bp.am/.</span> <span class="pre">alice/C</span> <span class="pre">dog/C)</span></code>.</p>
<p>The correspondences of the pronouns “her” and “she” to “Alice” are also used to infer gender, number and animacy. The “inferred_edges” field in the parser results is populated with the following hyperedges:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">gender</span><span class="o">/</span><span class="n">P</span><span class="o">/.</span> <span class="n">alice</span><span class="o">/</span><span class="n">Cp</span><span class="o">.</span><span class="n">s</span><span class="o">/</span><span class="n">en</span> <span class="n">female</span><span class="p">),</span>
<span class="p">(</span><span class="n">number</span><span class="o">/</span><span class="n">P</span><span class="o">/.</span> <span class="n">alice</span><span class="o">/</span><span class="n">Cp</span><span class="o">.</span><span class="n">s</span><span class="o">/</span><span class="n">en</span> <span class="n">singular</span><span class="p">),</span>
<span class="p">(</span><span class="n">animacy</span><span class="o">/</span><span class="n">P</span><span class="o">/.</span> <span class="n">alice</span><span class="o">/</span><span class="n">Cp</span><span class="o">.</span><span class="n">s</span><span class="o">/</span><span class="n">en</span> <span class="n">animate</span><span class="p">)</span>
</pre></div>
</div>
<dl>
<dt>To give the complete example::</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">parser</span> <span class="o">=</span> <span class="n">create_parser</span><span class="p">(</span><span class="n">lang</span><span class="o">=</span><span class="s1">&#39;en&#39;</span><span class="p">,</span> <span class="n">corefs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">parser</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s1">&#39;Alice says that she likes her dog.&#39;</span><span class="p">)</span>
<span class="go">{&#39;parses&#39;:</span>
<span class="go">    ({&#39;main_edge&#39;: (says/Pd.sr.|f--3s-/en alice/Cp.s/en (that/T/en (likes/P.so.|f--3s-/en she/Ci/en (her/Mp/en dog/Cc.s/en)))),</span>
<span class="go">      &#39;extra_edges&#39;: set(),</span>
<span class="go">      &#39;failed&#39;: False,</span>
<span class="go">      &#39;text&#39;: &#39;Alice says that she likes her dog.&#39;,</span>
<span class="go">      &#39;atom2word&#39;: {says/Pd.sr.|f--3s-/en: (&#39;says&#39;, 1),</span>
<span class="go">                    alice/Cp.s/en: (&#39;Alice&#39;, 0),</span>
<span class="go">                    that/T/en: (&#39;that&#39;, 2),</span>
<span class="go">                    likes/P.so.|f--3s-/en: (&#39;likes&#39;, 4),</span>
<span class="go">                    she/Ci/en: (&#39;she&#39;, 3),</span>
<span class="go">                    her/Mp/en: (&#39;her&#39;, 5),</span>
<span class="go">                    dog/Cc.s/en: (&#39;dog&#39;, 6)},</span>
<span class="go">      &#39;atom2token&#39;: {alice/Cp.s/en: Alice,</span>
<span class="go">                     that/T/en: that,</span>
<span class="go">                     she/Ci/en: she,</span>
<span class="go">                     her/Mp/en: her,</span>
<span class="go">                     dog/Cc.s/en: dog,</span>
<span class="go">                     says/Pd.sr.|f--3s-/en: says,</span>
<span class="go">                     likes/P.so.|f--3s-/en: likes},</span>
<span class="go">      &#39;spacy_sentence&#39;: Alice says that she likes her dog.,</span>
<span class="go">      &#39;resolved_corefs&#39;: (says/Pd.sr.|f--3s-/en alice/Cp.s/en (that/T/en (likes/P.so.|f--3s-/en alice/Cp.s/en (poss/Bp.am/. alice/Cp.s/en dog/Cc.s/en))))},),</span>
<span class="go"> &#39;inferred_edges&#39;: [(gender/P/. alice/Cp.s/en female),</span>
<span class="go">                    (number/P/. alice/Cp.s/en singular),</span>
<span class="go">                    (animacy/P/. alice/Cp.s/en animate)]}</span>
</pre></div>
</div>
</dd>
</dl>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="discovering-patterns.html" class="btn btn-neutral float-left" title="Discovering patterns" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="readers.html" class="btn btn-neutral float-right" title="Readers" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021 CNRS.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>